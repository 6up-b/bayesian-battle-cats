{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe6cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected rarity counts over next horizon:\n",
      "  Rare      : 20.71\n",
      "  Super     : 7.66\n",
      "  Uber      : 1.49\n",
      "  Legendary : 0.14\n",
      "\n",
      "per position most likely units:\n",
      "  Roll+01: Gardener Cat (10.63%), Pogo Cat (5.45%), Wheel Cat (5.31%), Cat Gunslinger (5.22%), Welterweight Cat (4.77%), Fortune Teller Cat (4.03%)\n",
      "  Roll+02: Viking Cat (8.68%), Cat Gunslinger (7.28%), Tin Cat (6.66%), Salon Cat (5.38%), Matador Cat (5.22%), Fortune Teller Cat (5.10%)\n",
      "  Roll+03: Bishop Cat (7.81%), Pirate Cat (6.40%), Thief Cat (5.07%), Salon Cat (5.06%), Swordsman Cat (5.04%), Wheel Cat (4.19%)\n",
      "  Roll+04: Wheel Cat (6.65%), Stilts Cat (6.58%), Wushu Cat (6.07%), Mer-Cat (5.39%), Welterweight Cat (5.28%), Bishop Cat (5.06%)\n",
      "  Roll+05: Tin Cat (7.51%), Cat Gunslinger (6.36%), Wheel Cat (5.20%), Gardener Cat (4.81%), Rocker Cat (4.05%), Nerd Cat (3.95%)\n",
      "  Roll+06: Onmyoji Cat (10.19%), Welterweight Cat (5.22%), Fencer Cat (5.10%), Archer Cat (4.28%), Mer-Cat (4.26%), Swordsman Cat (3.99%)\n",
      "  Roll+07: Shaman Cat (6.42%), Swordsman Cat (4.83%), Tin Cat (4.12%), Salon Cat (3.85%), Swimmer Cat (3.85%), Archer Cat (3.79%)\n",
      "  Roll+08: Shaman Cat (6.76%), Viking Cat (6.32%), Onmyoji Cat (4.32%), Welterweight Cat (4.10%), Rover Cat (4.08%), Fortune Teller Cat (3.94%)\n",
      "  Roll+09: Onmyoji Cat (7.47%), Wheel Cat (6.28%), Archer Cat (5.21%), Rocker Cat (5.10%), Viking Cat (4.09%), Witch Cat (4.06%)\n",
      "  Roll+10: Viking Cat (6.49%), Bishop Cat (6.46%), Gardener Cat (5.02%), Witch Cat (4.83%), Wushu Cat (4.69%), Thief Cat (4.02%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bayesian (particle / ABC) seed inference + next-30-roll prediction\n",
    "for Battle Cats–style deterministic RNG (xorshift <<13, >>17, <<15),\n",
    "\n",
    "Reads banner paste from a local file: paste.txt\n",
    "\n",
    "Usage:\n",
    "  1) Save your banner paste into paste.txt (same folder as this script)\n",
    "  2) Edit observed_rolls below (your 4 rolls)\n",
    "  3) Run: python bc_bayes_seed.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Banner model + parser\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Banner:\n",
    "    rate_cumsum: List[int]               # e.g. [6970, 9470, 9970, 10000]\n",
    "    units_by_rarity: List[List[str]]     # [Rare[], Super[], Uber[], Legendary[]]\n",
    "    rerollable_rarities: List[int]       # usually [0] for Rare\n",
    "\n",
    "RARITY_ORDER = [\"Rare\", \"Super\", \"Uber\", \"Legendary\"]\n",
    "\n",
    "def _parse_units_with_indices(units_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse \"0 Wushu Cat, 1 Matador Cat, 2 Rover Cat, ...\" into list ordered by index.\n",
    "    \"\"\"\n",
    "    units_str = units_str.strip()\n",
    "    if not units_str:\n",
    "        return []\n",
    "\n",
    "    pattern = re.compile(r\"(\\d+)\\s+([^,]+)(?:,|$)\")\n",
    "    found = pattern.findall(units_str)\n",
    "    if not found:\n",
    "        return []\n",
    "\n",
    "    idx_to_name: Dict[int, str] = {}\n",
    "    for idx_s, name in found:\n",
    "        idx_to_name[int(idx_s)] = name.strip()\n",
    "\n",
    "    return [idx_to_name[i] for i in sorted(idx_to_name.keys())]\n",
    "\n",
    "def parse_banner_paste_real(paste: str) -> Banner:\n",
    "    \"\"\"\n",
    "    Parses lines like:\n",
    "      Rare: 69.7% (25 cats) 0 Wushu Cat, 1 Matador Cat, ...\n",
    "    The paste can include headers/indentation; we scan and extract the relevant lines.\n",
    "    \"\"\"\n",
    "    lines = [ln.strip() for ln in paste.splitlines() if ln.strip()]\n",
    "    relevant: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    line_regex = re.compile(\n",
    "        r\"^(?P<rarity>Rare|Super|Uber|Legendary):\\s+\"\n",
    "        r\"(?P<rate>[\\d.]+)%\\s+\\(\\d+\\s+cats\\)\\s*(?P<units>.*)$\"\n",
    "    )\n",
    "\n",
    "    for ln in lines:\n",
    "        m = line_regex.match(ln)\n",
    "        if not m:\n",
    "            continue\n",
    "        rarity = m.group(\"rarity\")\n",
    "        rate_pct = float(m.group(\"rate\"))\n",
    "        units_str = m.group(\"units\").strip()\n",
    "\n",
    "        slots = int(round(rate_pct * 100))  # percent -> slots out of 10000\n",
    "        units = _parse_units_with_indices(units_str)\n",
    "\n",
    "        relevant[rarity] = {\"slots\": slots, \"units\": units}\n",
    "\n",
    "    slots_list: List[int] = []\n",
    "    units_by_rarity: List[List[str]] = []\n",
    "    for r in RARITY_ORDER:\n",
    "        if r not in relevant:\n",
    "            slots_list.append(0)\n",
    "            units_by_rarity.append([])\n",
    "        else:\n",
    "            slots_list.append(int(relevant[r][\"slots\"]))\n",
    "            units_by_rarity.append(list(relevant[r][\"units\"]))\n",
    "\n",
    "    cumsum: List[int] = []\n",
    "    s = 0\n",
    "    for v in slots_list:\n",
    "        s += v\n",
    "        cumsum.append(s)\n",
    "\n",
    "    # Force final threshold to 10000; clamp earlier thresholds to stay monotone\n",
    "    if cumsum:\n",
    "        cumsum[-1] = 10000\n",
    "        for i in range(len(cumsum) - 2, -1, -1):\n",
    "            cumsum[i] = min(cumsum[i], cumsum[i + 1])\n",
    "\n",
    "    # Matches your JS worker behavior: immediate-dupe reroll only for Rare\n",
    "    return Banner(rate_cumsum=cumsum, units_by_rarity=units_by_rarity, rerollable_rarities=[0])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# RNG + roll simulation (matches your JS worker)\n",
    "# -----------------------------\n",
    "\n",
    "def advance_seed(seed: int) -> int:\n",
    "    seed &= 0xFFFFFFFF\n",
    "    seed ^= ((seed << 13) & 0xFFFFFFFF)\n",
    "    seed ^= (seed >> 17)\n",
    "    seed ^= ((seed << 15) & 0xFFFFFFFF)\n",
    "    return seed & 0xFFFFFFFF\n",
    "\n",
    "def get_rarity(seed: int, rate_cumsum: Sequence[int]) -> int:\n",
    "    x = seed % 10000\n",
    "    for i, thr in enumerate(rate_cumsum):\n",
    "        if x < thr:\n",
    "            return i\n",
    "    return len(rate_cumsum) - 1\n",
    "\n",
    "def get_unit(seed: int, units: Sequence[str], removed_index: int = -1) -> Tuple[int, str]:\n",
    "    n = len(units)\n",
    "    if n == 0:\n",
    "        return -1, \"<EMPTY_POOL>\"\n",
    "    if removed_index == -1:\n",
    "        idx = seed % n\n",
    "        return idx, units[idx]\n",
    "    if n <= 1:\n",
    "        return -1, \"<EMPTY_POOL>\"\n",
    "    idx = seed % (n - 1)\n",
    "    if idx >= removed_index:\n",
    "        idx += 1\n",
    "    return idx, units[idx]\n",
    "\n",
    "def simulate_rolls(seed0: int, banner: Banner, n_rolls: int, *, apply_dupe_reroll: bool = True) -> Tuple[List[str], int]:\n",
    "    seed = seed0 & 0xFFFFFFFF\n",
    "    out: List[str] = []\n",
    "    last_roll: Optional[str] = None\n",
    "\n",
    "    for _ in range(n_rolls):\n",
    "        seed = advance_seed(seed)\n",
    "        rarity = get_rarity(seed, banner.rate_cumsum)\n",
    "\n",
    "        seed = advance_seed(seed)\n",
    "        units = banner.units_by_rarity[rarity]\n",
    "        unit_idx, unit_id = get_unit(seed, units)\n",
    "\n",
    "        if (\n",
    "            apply_dupe_reroll\n",
    "            and last_roll is not None\n",
    "            and unit_id == last_roll\n",
    "            and rarity in banner.rerollable_rarities\n",
    "        ):\n",
    "            seed = advance_seed(seed)\n",
    "            _, rerolled_id = get_unit(seed, units, removed_index=unit_idx)\n",
    "            out.append(rerolled_id)\n",
    "            last_roll = rerolled_id\n",
    "        else:\n",
    "            out.append(unit_id)\n",
    "            last_roll = unit_id\n",
    "\n",
    "    return out, seed\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Bayesian posterior over seeds (particles / ABC)\n",
    "# -----------------------------\n",
    "\n",
    "def log_likelihood(predicted: Sequence[str], observed: Sequence[str], *, epsilon: float, banner: Banner) -> float:\n",
    "    if len(predicted) != len(observed):\n",
    "        raise ValueError(\"predicted and observed length mismatch\")\n",
    "    if not (0.0 <= epsilon < 1.0):\n",
    "        raise ValueError(\"epsilon must be in [0,1)\")\n",
    "\n",
    "    all_units = [u for pool in banner.units_by_rarity for u in pool]\n",
    "    q = 1.0 / max(1, len(all_units))\n",
    "\n",
    "    ll = 0.0\n",
    "    for p, y in zip(predicted, observed):\n",
    "        if p == y:\n",
    "            ll += math.log(max(1e-300, 1.0 - epsilon))\n",
    "        else:\n",
    "            ll += math.log(max(1e-300, epsilon * q))\n",
    "    return ll\n",
    "\n",
    "def sample_posterior_seeds(\n",
    "    banner: Banner,\n",
    "    observed_rolls: Sequence[str],\n",
    "    *,\n",
    "    num_particles: int = 120_000,\n",
    "    epsilon: float = 0.03,\n",
    "    rng_seed: int = 12345,\n",
    "    apply_dupe_reroll: bool = True,\n",
    ") -> Tuple[List[int], List[float]]:\n",
    "    random.seed(rng_seed)\n",
    "\n",
    "    m = len(observed_rolls)\n",
    "    seeds: List[int] = []\n",
    "    logw: List[float] = []\n",
    "\n",
    "    for _ in range(num_particles):\n",
    "        s0 = random.getrandbits(32) or 1\n",
    "\n",
    "        pred, _ = simulate_rolls(s0, banner, m, apply_dupe_reroll=apply_dupe_reroll)\n",
    "\n",
    "        if epsilon == 0.0:\n",
    "            if pred == list(observed_rolls):\n",
    "                seeds.append(s0)\n",
    "                logw.append(0.0)\n",
    "        else:\n",
    "            seeds.append(s0)\n",
    "            logw.append(log_likelihood(pred, observed_rolls, epsilon=epsilon, banner=banner))\n",
    "\n",
    "    if not seeds:\n",
    "        return [], []\n",
    "\n",
    "    mx = max(logw)\n",
    "    w = [math.exp(lw - mx) for lw in logw]\n",
    "    s = sum(w)\n",
    "    w = [wi / s for wi in w] if s else [1.0 / len(w)] * len(w)\n",
    "    return seeds, w\n",
    "\n",
    "def resample_multinomial(seeds: Sequence[int], weights: Sequence[float], n: int, *, rng_seed: int) -> List[int]:\n",
    "    random.seed(rng_seed)\n",
    "    if not seeds:\n",
    "        return []\n",
    "\n",
    "    cdf: List[float] = []\n",
    "    s = 0.0\n",
    "    for w in weights:\n",
    "        s += w\n",
    "        cdf.append(s)\n",
    "\n",
    "    out: List[int] = []\n",
    "    for _ in range(n):\n",
    "        r = random.random()\n",
    "        lo, hi = 0, len(cdf) - 1\n",
    "        while lo < hi:\n",
    "            mid = (lo + hi) // 2\n",
    "            if r <= cdf[mid]:\n",
    "                hi = mid\n",
    "            else:\n",
    "                lo = mid + 1\n",
    "        out.append(seeds[lo])\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Predictive distribution for next K rolls\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class PredictiveSummary:\n",
    "    per_position_unit_probs: List[Dict[str, float]]\n",
    "    expected_rarity_counts: Dict[str, float]\n",
    "\n",
    "def predictive_next_k(\n",
    "    banner: Banner,\n",
    "    observed_rolls: Sequence[str],\n",
    "    *,\n",
    "    k: int = 30,\n",
    "    num_particles: int = 120_000,\n",
    "    epsilon: float = 0.03,\n",
    "    posterior_paths: int = 10_000,\n",
    "    rng_seed: int = 12345,\n",
    "    apply_dupe_reroll: bool = True,\n",
    ") -> PredictiveSummary:\n",
    "    seeds, weights = sample_posterior_seeds(\n",
    "        banner,\n",
    "        observed_rolls,\n",
    "        num_particles=num_particles,\n",
    "        epsilon=epsilon,\n",
    "        rng_seed=rng_seed,\n",
    "        apply_dupe_reroll=apply_dupe_reroll,\n",
    "    )\n",
    "    if not seeds:\n",
    "        raise RuntimeError(\"No posterior mass. Increase epsilon or num_particles.\")\n",
    "\n",
    "    posterior_seeds = resample_multinomial(seeds, weights, posterior_paths, rng_seed=rng_seed + 1)\n",
    "\n",
    "    unit_to_rarity: Dict[str, int] = {}\n",
    "    for ri, pool in enumerate(banner.units_by_rarity):\n",
    "        for u in pool:\n",
    "            unit_to_rarity.setdefault(u, ri)\n",
    "\n",
    "    m = len(observed_rolls)\n",
    "    per_pos_counts: List[Counter] = [Counter() for _ in range(k)]\n",
    "    rarity_sum = Counter()\n",
    "\n",
    "    for s0 in posterior_seeds:\n",
    "        full, _ = simulate_rolls(s0, banner, m + k, apply_dupe_reroll=apply_dupe_reroll)\n",
    "        future = full[m:]\n",
    "\n",
    "        for i, u in enumerate(future):\n",
    "            per_pos_counts[i][u] += 1\n",
    "            ri = unit_to_rarity.get(u, None)\n",
    "            if ri is not None:\n",
    "                rarity_sum[ri] += 1\n",
    "\n",
    "    n_paths = len(posterior_seeds)\n",
    "\n",
    "    per_position_probs: List[Dict[str, float]] = []\n",
    "    for c in per_pos_counts:\n",
    "        total = sum(c.values())\n",
    "        per_position_probs.append({u: cnt / total for u, cnt in c.items()} if total else {})\n",
    "\n",
    "    expected_rarity_counts: Dict[str, float] = {}\n",
    "    for ri, tot in rarity_sum.items():\n",
    "        expected_rarity_counts[RARITY_ORDER[ri]] = tot / n_paths\n",
    "\n",
    "    return PredictiveSummary(per_position_unit_probs=per_position_probs, expected_rarity_counts=expected_rarity_counts)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Pretty printing\n",
    "# -----------------------------\n",
    "\n",
    "def topk(probs: Dict[str, float], k: int = 5) -> List[Tuple[str, float]]:\n",
    "    return sorted(probs.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "def print_summary(summary: PredictiveSummary, *, top_k: int = 5, positions: int = 10) -> None:\n",
    "    print(\"expected rarity counts over next horizon:\")\n",
    "    for r in RARITY_ORDER:\n",
    "        if r in summary.expected_rarity_counts:\n",
    "            print(f\"  {r:10s}: {summary.expected_rarity_counts[r]:.2f}\")\n",
    "    print()\n",
    "    print(\"per position most likely units:\")\n",
    "    for i, probs in enumerate(summary.per_position_unit_probs[:positions], start=1):\n",
    "        best = topk(probs, top_k)\n",
    "        s = \", \".join([f\"{u} ({p:.2%})\" for u, p in best])\n",
    "        print(f\"  Roll+{i:02d}: {s}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main: load paste from paste.txt\n",
    "# -----------------------------\n",
    "\n",
    "def load_paste_file(path: str = \"paste.txt\") -> str:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find {path!r}. Put your banner paste in a file named paste.txt \"\n",
    "            f\"in the same folder as this script (or pass a full path).\"\n",
    "        )\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    banner_paste = load_paste_file(\"paste.txt\")\n",
    "    banner = parse_banner_paste_real(banner_paste)\n",
    "\n",
    "    # Edit these with your observed rolls (must match unit names in the paste exactly)\n",
    "    observed_rolls = [\"Viking Cat\", \"Tin Cat\", \"Fortune Teller Cat\", \"Archer Cat\", \"Bishop Cat\", \"Gold Cat\"]\n",
    "\n",
    "    summary = predictive_next_k(\n",
    "        banner,\n",
    "        observed_rolls,\n",
    "        k=30,\n",
    "        num_particles=300_000,\n",
    "        epsilon=0.03,\n",
    "        posterior_paths=10_000,\n",
    "        rng_seed=12345,\n",
    "        apply_dupe_reroll=True,\n",
    "    )\n",
    "\n",
    "    print_summary(summary, top_k=6, positions=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ca3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches observed? True\n",
      "Seed after 7: 2099626319\n",
      "Next cat: Kasa Jizo\n",
      "Seed after 8: 844176769\n"
     ]
    }
   ],
   "source": [
    "def simulate_n(seed0: int, banner, n: int):\n",
    "    seed = seed0 & 0xFFFFFFFF\n",
    "    out = []\n",
    "    last = None\n",
    "\n",
    "    for _ in range(n):\n",
    "        seed = advance_seed(seed)\n",
    "        rarity = get_rarity(seed, banner.rate_cumsum)\n",
    "\n",
    "        seed = advance_seed(seed)\n",
    "        units = banner.units_by_rarity[rarity]\n",
    "        unit_idx, unit_id = get_unit(seed, units)\n",
    "\n",
    "        if last is not None and unit_id == last and rarity in banner.rerollable_rarities:\n",
    "            seed = advance_seed(seed)\n",
    "            _, rerolled = get_unit(seed, units, removed_index=unit_idx)\n",
    "            out.append(rerolled)\n",
    "            last = rerolled\n",
    "        else:\n",
    "            out.append(unit_id)\n",
    "            last = unit_id\n",
    "\n",
    "    return out, seed\n",
    "\n",
    "# --- your case ---\n",
    "seed_before = 659650523\n",
    "observed = [\"Viking Cat\", \"Tin Cat\", \"Fortune Teller Cat\", \"Archer Cat\", \"Bishop Cat\", \"Gold Cat\", \"Pirate Cat\"]\n",
    "\n",
    "pred6, seed_after6 = simulate_n(seed_before, banner, 7)\n",
    "print(\"matches observed?\", pred6 == observed)\n",
    "print(\"Seed after 7:\", seed_after6)  # should be 3183349844\n",
    "\n",
    "pred7, seed_after7 = simulate_n(seed_before, banner, 8)\n",
    "print(\"Next cat:\", pred7[-1])        # should be Pirate Cat\n",
    "print(\"Seed after 8:\", seed_after7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35de399",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seed_seeker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82091/4216979394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Import the cython extension (build first!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseed_seeker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mRARITY_ORDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Rare\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Super\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Uber\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Legendary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seed_seeker'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Sequence, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "# Import the cython extension (build first!)\n",
    "import seed_seeker\n",
    "\n",
    "RARITY_ORDER = [\"Rare\", \"Super\", \"Uber\", \"Legendary\"]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Banner:\n",
    "    rate_cumsum: List[int]\n",
    "    units_by_rarity: List[List[str]]\n",
    "    rerollable_rarities: List[int]\n",
    "\n",
    "def _parse_units_with_indices(units_str: str) -> List[str]:\n",
    "    units_str = units_str.strip()\n",
    "    if not units_str:\n",
    "        return []\n",
    "    pat = re.compile(r\"(\\d+)\\s+([^,]+)(?:,|$)\")\n",
    "    found = pat.findall(units_str)\n",
    "    idx_to_name: Dict[int, str] = {int(i): name.strip() for i, name in found}\n",
    "    return [idx_to_name[i] for i in sorted(idx_to_name)]\n",
    "\n",
    "def parse_banner_paste(paste: str) -> Banner:\n",
    "    lines = [ln.strip() for ln in paste.splitlines() if ln.strip()]\n",
    "    relevant: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    line_regex = re.compile(\n",
    "        r\"^(?P<rarity>Rare|Super|Uber|Legendary):\\s+\"\n",
    "        r\"(?P<rate>[\\d.]+)%\\s+\\(\\d+\\s+cats\\)\\s*(?P<units>.*)$\"\n",
    "    )\n",
    "\n",
    "    for ln in lines:\n",
    "        m = line_regex.match(ln)\n",
    "        if not m:\n",
    "            continue\n",
    "        rarity = m.group(\"rarity\")\n",
    "        rate_pct = float(m.group(\"rate\"))\n",
    "        slots = int(round(rate_pct * 100))\n",
    "        units = _parse_units_with_indices(m.group(\"units\"))\n",
    "        relevant[rarity] = {\"slots\": slots, \"units\": units}\n",
    "\n",
    "    slots_list, pools = [], []\n",
    "    for r in RARITY_ORDER:\n",
    "        if r not in relevant:\n",
    "            slots_list.append(0)\n",
    "            pools.append([])\n",
    "        else:\n",
    "            slots_list.append(relevant[r][\"slots\"])\n",
    "            pools.append(relevant[r][\"units\"])\n",
    "\n",
    "    cumsum = []\n",
    "    s = 0\n",
    "    for v in slots_list:\n",
    "        s += v\n",
    "        cumsum.append(s)\n",
    "\n",
    "    # Fix rounding drift\n",
    "    cumsum[-1] = 10000\n",
    "    for i in range(len(cumsum)-2, -1, -1):\n",
    "        cumsum[i] = min(cumsum[i], cumsum[i+1])\n",
    "\n",
    "    return Banner(rate_cumsum=cumsum, units_by_rarity=pools, rerollable_rarities=[0])\n",
    "\n",
    "def load_paste(path: str = \"paste.txt\") -> str:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {path}\")\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "# ---- deterministic simulator in Python for prediction (fast enough once seeds known) ----\n",
    "\n",
    "def advance_seed(seed: int) -> int:\n",
    "    seed &= 0xFFFFFFFF\n",
    "    seed ^= ((seed << 13) & 0xFFFFFFFF)\n",
    "    seed ^= (seed >> 17)\n",
    "    seed ^= ((seed << 15) & 0xFFFFFFFF)\n",
    "    return seed & 0xFFFFFFFF\n",
    "\n",
    "def get_rarity(seed: int, rate_cumsum: Sequence[int]) -> int:\n",
    "    x = seed % 10000\n",
    "    for i, thr in enumerate(rate_cumsum):\n",
    "        if x < thr:\n",
    "            return i\n",
    "    return len(rate_cumsum) - 1\n",
    "\n",
    "def get_unit_index(seed: int, n: int, removed_index: int = -1) -> int:\n",
    "    if n <= 0:\n",
    "        return -1\n",
    "    if removed_index < 0:\n",
    "        return seed % n\n",
    "    if n <= 1:\n",
    "        return -1\n",
    "    idx = seed % (n - 1)\n",
    "    if idx >= removed_index:\n",
    "        idx += 1\n",
    "    return idx\n",
    "\n",
    "def simulate_next_k(seed0: int, banner_units_int: List[List[int]], rate_cumsum: List[int], rerollable: List[int],\n",
    "                    observed_len: int, k: int) -> List[int]:\n",
    "    seed = seed0 & 0xFFFFFFFF\n",
    "    last = None\n",
    "    out: List[int] = []\n",
    "\n",
    "    reroll_set = set(rerollable)\n",
    "\n",
    "    for _ in range(observed_len + k):\n",
    "        seed = advance_seed(seed)\n",
    "        rarity = get_rarity(seed, rate_cumsum)\n",
    "\n",
    "        seed = advance_seed(seed)\n",
    "        pool = banner_units_int[rarity]\n",
    "        n = len(pool)\n",
    "        idx = get_unit_index(seed, n, -1)\n",
    "        unit_id = pool[idx] if idx >= 0 else -1\n",
    "\n",
    "        if last is not None and rarity in reroll_set and unit_id == last:\n",
    "            seed = advance_seed(seed)\n",
    "            idx2 = get_unit_index(seed, n, idx)\n",
    "            unit_id = pool[idx2] if idx2 >= 0 else -1\n",
    "\n",
    "        out.append(unit_id)\n",
    "        last = unit_id\n",
    "\n",
    "    return out[observed_len:]\n",
    "\n",
    "# ---- Bayes over exact seeds + prediction mixture ----\n",
    "\n",
    "def posterior_over_exact_seeds(exact_seeds: List[int], prior: Dict[int, float] | None = None) -> Dict[int, float]:\n",
    "    if not exact_seeds:\n",
    "        return {}\n",
    "    if prior is None:\n",
    "        w = 1.0 / len(exact_seeds)\n",
    "        return {s: w for s in exact_seeds}\n",
    "    # restrict + renormalize\n",
    "    total = sum(prior.get(s, 0.0) for s in exact_seeds)\n",
    "    if total <= 0:\n",
    "        w = 1.0 / len(exact_seeds)\n",
    "        return {s: w for s in exact_seeds}\n",
    "    return {s: prior.get(s, 0.0) / total for s in exact_seeds}\n",
    "\n",
    "def predictive_mixture(\n",
    "    seeds_posterior: Dict[int, float],\n",
    "    id_to_name: Dict[int, str],\n",
    "    banner_units_int: List[List[int]],\n",
    "    rate_cumsum: List[int],\n",
    "    rerollable: List[int],\n",
    "    observed_len: int,\n",
    "    k: int,\n",
    ") -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Returns per-position probability dicts for next k rolls.\n",
    "    \"\"\"\n",
    "    per_pos = [Counter() for _ in range(k)]\n",
    "\n",
    "    for s, w in seeds_posterior.items():\n",
    "        future = simulate_next_k(s, banner_units_int, rate_cumsum, rerollable, observed_len, k)\n",
    "        for i, uid in enumerate(future):\n",
    "            per_pos[i][uid] += w\n",
    "\n",
    "    # normalize each position (should already sum ~1)\n",
    "    out: List[Dict[str, float]] = []\n",
    "    for c in per_pos:\n",
    "        total = sum(c.values())\n",
    "        probs = {}\n",
    "        for uid, mass in c.items():\n",
    "            name = id_to_name.get(uid, f\"<id:{uid}>\")\n",
    "            probs[name] = float(mass / total) if total > 0 else 0.0\n",
    "        out.append(probs)\n",
    "    return out\n",
    "\n",
    "def topk(probs: Dict[str, float], k: int = 6) -> List[Tuple[str, float]]:\n",
    "    return sorted(probs.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    banner = parse_banner_paste(load_paste(\"paste.txt\"))\n",
    "\n",
    "    # Example observed rolls (edit these)\n",
    "    observed_rolls = [\"Viking Cat\", \"Tin Cat\", \"Fortune Teller Cat\", \"Archer Cat\", \"Bishop Cat\", \"Gold Cat\"]\n",
    "\n",
    "    # Build int IDs\n",
    "    name_to_id: Dict[str, int] = {}\n",
    "    id_to_name: Dict[int, str] = {}\n",
    "\n",
    "    def get_id(name: str) -> int:\n",
    "        if name not in name_to_id:\n",
    "            new_id = len(name_to_id) + 1\n",
    "            name_to_id[name] = new_id\n",
    "            id_to_name[new_id] = name\n",
    "        return name_to_id[name]\n",
    "\n",
    "    banner_units_int: List[List[int]] = []\n",
    "    for pool in banner.units_by_rarity:\n",
    "        banner_units_int.append([get_id(u) for u in pool])\n",
    "\n",
    "    observed_int = [get_id(u) for u in observed_rolls]\n",
    "\n",
    "    # --- EXACT seek ---\n",
    "    # IMPORTANT: Python+Cython brute force over all 2^32 seeds is still huge.\n",
    "    # If you already have a seed from elsewhere, you don't need seeking.\n",
    "    #\n",
    "    # Here we show how to search a specific range. Tune to your needs.\n",
    "    start_seed = 0\n",
    "    end_seed = 1_000_000  # demo range; expand as you like\n",
    "\n",
    "    exact = seed_seeker.seek_seeds(\n",
    "        start_seed,\n",
    "        end_seed,\n",
    "        banner.rate_cumsum,\n",
    "        banner_units_int,\n",
    "        banner.rerollable_rarities,\n",
    "        observed_int,\n",
    "        max_found=100,\n",
    "    )\n",
    "    print(f\"Exact seeds found in range [{start_seed}, {end_seed}): {exact}\")\n",
    "\n",
    "    # Bayes over exact set (uniform posterior by default)\n",
    "    post = posterior_over_exact_seeds(exact)\n",
    "\n",
    "    # Predict next 30\n",
    "    pred = predictive_mixture(\n",
    "        post,\n",
    "        id_to_name,\n",
    "        banner_units_int,\n",
    "        banner.rate_cumsum,\n",
    "        banner.rerollable_rarities,\n",
    "        observed_len=len(observed_int),\n",
    "        k=30,\n",
    "    )\n",
    "\n",
    "    for i in range(10):\n",
    "        best = topk(pred[i], 6)\n",
    "        s = \", \".join([f\"{u} ({p:.2%})\" for u, p in best])\n",
    "        print(f\"Roll+{i+1:02d}: {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc93d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--paste PASTE]\n",
      "                             [--posterior-pkl POSTERIOR_PKL] [--use-pickle]\n",
      "                             [--save-pickle] [--start START] [--end END]\n",
      "                             [--max-found MAX_FOUND] [--predict-k PREDICT_K]\n",
      "                             [--print-pos PRINT_POS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/chloe/.local/share/jupyter/runtime/kernel-75bfe12f-979b-422b-97b3-cf378b65122a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Sequence, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import seed_seeker  # compiled cython module\n",
    "\n",
    "RARITY_ORDER = [\"Rare\", \"Super\", \"Uber\", \"Legendary\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Banner parsing (paste.txt)\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Banner:\n",
    "    rate_cumsum: List[int]\n",
    "    units_by_rarity: List[List[str]]\n",
    "    rerollable_rarities: List[int]\n",
    "\n",
    "def _parse_units_with_indices(units_str: str) -> List[str]:\n",
    "    units_str = units_str.strip()\n",
    "    if not units_str:\n",
    "        return []\n",
    "    pat = re.compile(r\"(\\d+)\\s+([^,]+)(?:,|$)\")\n",
    "    found = pat.findall(units_str)\n",
    "    idx_to_name: Dict[int, str] = {int(i): name.strip() for i, name in found}\n",
    "    return [idx_to_name[i] for i in sorted(idx_to_name)]\n",
    "\n",
    "def parse_banner_paste(paste: str) -> Banner:\n",
    "    lines = [ln.strip() for ln in paste.splitlines() if ln.strip()]\n",
    "    relevant: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    line_regex = re.compile(\n",
    "        r\"^(?P<rarity>Rare|Super|Uber|Legendary):\\s+\"\n",
    "        r\"(?P<rate>[\\d.]+)%\\s+\\(\\d+\\s+cats\\)\\s*(?P<units>.*)$\"\n",
    "    )\n",
    "\n",
    "    for ln in lines:\n",
    "        m = line_regex.match(ln)\n",
    "        if not m:\n",
    "            continue\n",
    "        rarity = m.group(\"rarity\")\n",
    "        rate_pct = float(m.group(\"rate\"))\n",
    "        slots = int(round(rate_pct * 100))\n",
    "        units = _parse_units_with_indices(m.group(\"units\"))\n",
    "        relevant[rarity] = {\"slots\": slots, \"units\": units}\n",
    "\n",
    "    slots_list, pools = [], []\n",
    "    for r in RARITY_ORDER:\n",
    "        if r not in relevant:\n",
    "            slots_list.append(0)\n",
    "            pools.append([])\n",
    "        else:\n",
    "            slots_list.append(relevant[r][\"slots\"])\n",
    "            pools.append(relevant[r][\"units\"])\n",
    "\n",
    "    cumsum = []\n",
    "    s = 0\n",
    "    for v in slots_list:\n",
    "        s += v\n",
    "        cumsum.append(s)\n",
    "    cumsum[-1] = 10000\n",
    "    for i in range(len(cumsum) - 2, -1, -1):\n",
    "        cumsum[i] = min(cumsum[i], cumsum[i + 1])\n",
    "\n",
    "    return Banner(rate_cumsum=cumsum, units_by_rarity=pools, rerollable_rarities=[0])\n",
    "\n",
    "def load_paste(path: str = \"paste.txt\") -> str:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {path}\")\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Deterministic simulator (Python) for prediction mixture once posterior small\n",
    "# -----------------------------\n",
    "\n",
    "def advance_seed(seed: int) -> int:\n",
    "    seed &= 0xFFFFFFFF\n",
    "    seed ^= ((seed << 13) & 0xFFFFFFFF)\n",
    "    seed ^= (seed >> 17)\n",
    "    seed ^= ((seed << 15) & 0xFFFFFFFF)\n",
    "    return seed & 0xFFFFFFFF\n",
    "\n",
    "def get_rarity(seed: int, rate_cumsum: Sequence[int]) -> int:\n",
    "    x = seed % 10000\n",
    "    for i, thr in enumerate(rate_cumsum):\n",
    "        if x < thr:\n",
    "            return i\n",
    "    return len(rate_cumsum) - 1\n",
    "\n",
    "def get_unit_index(seed: int, n: int, removed_index: int = -1) -> int:\n",
    "    if n <= 0:\n",
    "        return -1\n",
    "    if removed_index < 0:\n",
    "        return seed % n\n",
    "    if n <= 1:\n",
    "        return -1\n",
    "    idx = seed % (n - 1)\n",
    "    if idx >= removed_index:\n",
    "        idx += 1\n",
    "    return idx\n",
    "\n",
    "def simulate_next_k_from_seed_before(\n",
    "    seed_before: int,\n",
    "    banner_units_int: List[List[int]],\n",
    "    rate_cumsum: List[int],\n",
    "    rerollable: List[int],\n",
    "    observed_len: int,\n",
    "    k: int,\n",
    ") -> List[int]:\n",
    "    seed = seed_before & 0xFFFFFFFF\n",
    "    last = None\n",
    "    out: List[int] = []\n",
    "    reroll_set = set(rerollable)\n",
    "\n",
    "    for _ in range(observed_len + k):\n",
    "        seed = advance_seed(seed)\n",
    "        rarity = get_rarity(seed, rate_cumsum)\n",
    "\n",
    "        seed = advance_seed(seed)\n",
    "        pool = banner_units_int[rarity]\n",
    "        n = len(pool)\n",
    "        idx = get_unit_index(seed, n, -1)\n",
    "        unit_id = pool[idx] if idx >= 0 else -1\n",
    "\n",
    "        if last is not None and rarity in reroll_set and unit_id == last:\n",
    "            seed = advance_seed(seed)\n",
    "            idx2 = get_unit_index(seed, n, idx)\n",
    "            unit_id = pool[idx2] if idx2 >= 0 else -1\n",
    "\n",
    "        out.append(unit_id)\n",
    "        last = unit_id\n",
    "\n",
    "    return out[observed_len:]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Posterior management: over seed_after values (chaining)\n",
    "# -----------------------------\n",
    "\n",
    "Posterior = Dict[int, float]  # maps seed_before_next_roll -> probability mass\n",
    "\n",
    "def posterior_uniform(states: List[int]) -> Posterior:\n",
    "    if not states:\n",
    "        return {}\n",
    "    w = 1.0 / len(states)\n",
    "    return {s: w for s in states}\n",
    "\n",
    "def posterior_from_matches_seed_after(matches: List[Tuple[int, int]], prior_over_seed_before: Posterior | None) -> Posterior:\n",
    "    \"\"\"\n",
    "    matches: list of (seed_before, seed_after)\n",
    "    prior_over_seed_before: posterior from previous iteration over seed_before values.\n",
    "      If None: treat seed_before prior as uniform over the found matches.\n",
    "\n",
    "    Returns posterior over seed_after values.\n",
    "    \"\"\"\n",
    "    if not matches:\n",
    "        return {}\n",
    "\n",
    "    # If no prior, uniform over matches\n",
    "    if prior_over_seed_before is None:\n",
    "        counts = Counter(seed_after for _, seed_after in matches)\n",
    "        total = sum(counts.values())\n",
    "        return {s_after: c / total for s_after, c in counts.items()}\n",
    "\n",
    "    # With prior: mass on a match = prior(seed_before); then aggregate by seed_after\n",
    "    acc = Counter()\n",
    "    total_mass = 0.0\n",
    "    for seed_before, seed_after in matches:\n",
    "        w = prior_over_seed_before.get(seed_before, 0.0)\n",
    "        if w > 0:\n",
    "            acc[seed_after] += w\n",
    "            total_mass += w\n",
    "\n",
    "    if total_mass <= 0:\n",
    "        # fallback: uniform over seed_after in matches\n",
    "        return posterior_uniform(list({s_after for _, s_after in matches}))\n",
    "\n",
    "    return {s_after: float(mass / total_mass) for s_after, mass in acc.items()}\n",
    "\n",
    "def save_posterior(path: str, posterior: Posterior) -> None:\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(posterior, f)\n",
    "\n",
    "def load_posterior(path: str) -> Posterior:\n",
    "    with open(path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Pickle did not contain a dict posterior\")\n",
    "    # ensure int->float\n",
    "    out: Posterior = {}\n",
    "    for k, v in obj.items():\n",
    "        out[int(k)] = float(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prediction mixture from posterior\n",
    "# -----------------------------\n",
    "\n",
    "def predictive_mixture(\n",
    "    posterior_seed_before: Posterior,\n",
    "    id_to_name: Dict[int, str],\n",
    "    banner_units_int: List[List[int]],\n",
    "    rate_cumsum: List[int],\n",
    "    rerollable: List[int],\n",
    "    observed_len: int,\n",
    "    k: int,\n",
    ") -> List[Dict[str, float]]:\n",
    "    per_pos = [Counter() for _ in range(k)]\n",
    "    for seed_before, w in posterior_seed_before.items():\n",
    "        future = simulate_next_k_from_seed_before(seed_before, banner_units_int, rate_cumsum, rerollable, observed_len, k)\n",
    "        for i, uid in enumerate(future):\n",
    "            per_pos[i][uid] += w\n",
    "\n",
    "    out: List[Dict[str, float]] = []\n",
    "    for c in per_pos:\n",
    "        total = sum(c.values())\n",
    "        probs: Dict[str, float] = {}\n",
    "        for uid, mass in c.items():\n",
    "            probs[id_to_name.get(uid, f\"<id:{uid}>\")] = float(mass / total) if total > 0 else 0.0\n",
    "        out.append(probs)\n",
    "    return out\n",
    "\n",
    "def topk(probs: Dict[str, float], k: int = 6) -> List[Tuple[str, float]]:\n",
    "    return sorted(probs.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--paste\", default=\"paste.txt\")\n",
    "    ap.add_argument(\"--posterior-pkl\", default=\"posterior.pkl\")\n",
    "    ap.add_argument(\"--use-pickle\", action=\"store_true\", help=\"Load prior posterior from pickle (if present).\")\n",
    "    ap.add_argument(\"--save-pickle\", action=\"store_true\", help=\"Save updated posterior to pickle after this update.\")\n",
    "    ap.add_argument(\"--start\", type=int, default=0, help=\"Start seed (inclusive) for seeking (only used if no prior pickle).\")\n",
    "    ap.add_argument(\"--end\", type=int, default=1_000_000, help=\"End seed (exclusive) for seeking (only used if no prior pickle).\")\n",
    "    ap.add_argument(\"--max-found\", type=int, default=0, help=\"Stop after this many matches (0 = all in range).\")\n",
    "    ap.add_argument(\"--predict-k\", type=int, default=30)\n",
    "    ap.add_argument(\"--print-pos\", type=int, default=10)\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    banner = parse_banner_paste(load_paste(args.paste))\n",
    "\n",
    "    # EDIT HERE or load from elsewhere (keep it simple: hardcode for now)\n",
    "    observed_rolls = [\"Viking Cat\", \"Tin Cat\", \"Fortune Teller Cat\", \"Archer Cat\", \"Bishop Cat\", \"Gold Cat\"]\n",
    "\n",
    "    # Map names to ints\n",
    "    name_to_id: Dict[str, int] = {}\n",
    "    id_to_name: Dict[int, str] = {}\n",
    "\n",
    "    def get_id(name: str) -> int:\n",
    "        if name not in name_to_id:\n",
    "            new_id = len(name_to_id) + 1\n",
    "            name_to_id[name] = new_id\n",
    "            id_to_name[new_id] = name\n",
    "        return name_to_id[name]\n",
    "\n",
    "    banner_units_int: List[List[int]] = []\n",
    "    for pool in banner.units_by_rarity:\n",
    "        banner_units_int.append([get_id(u) for u in pool])\n",
    "\n",
    "    observed_int = [get_id(u) for u in observed_rolls]\n",
    "\n",
    "    # Load prior posterior if requested and exists\n",
    "    prior: Posterior | None = None\n",
    "    if args.use_pickle and Path(args.posterior_pkl).exists():\n",
    "        prior = load_posterior(args.posterior_pkl)\n",
    "        print(f\"Loaded prior posterior from {args.posterior_pkl} with {len(prior)} states.\")\n",
    "    else:\n",
    "        print(\"No prior posterior loaded (starting fresh).\")\n",
    "\n",
    "    # Exact match seeking:\n",
    "    # - If prior exists, we seek from each prior seed_before state directly by running seeker over tiny ranges?\n",
    "    #   Not necessary: you already have specific seed_before candidates, so you can just simulate forward.\n",
    "    #   BUT: since you requested Cython seeker usage, we’ll use it in two modes:\n",
    "    #\n",
    "    # Mode A: no prior -> brute seek in [start,end)\n",
    "    # Mode B: prior exists -> for each prior seed_before, check exact match by seeking range [seed_before, seed_before+1)\n",
    "    #\n",
    "    matches: List[Tuple[int, int]] = []\n",
    "\n",
    "    if prior is None:\n",
    "        # Full range search\n",
    "        matches = seed_seeker.seek_seeds_before_after(\n",
    "            args.start, args.end,\n",
    "            banner.rate_cumsum,\n",
    "            banner_units_int,\n",
    "            banner.rerollable_rarities,\n",
    "            observed_int,\n",
    "            args.max_found\n",
    "        )\n",
    "        print(f\"Matches found in range [{args.start},{args.end}): {len(matches)}\")\n",
    "    else:\n",
    "        # Check each prior state as the candidate \"seed_before\" for this iteration\n",
    "        # by searching the 1-seed range [s, s+1)\n",
    "        for s_before, w in sorted(prior.items(), key=lambda kv: -kv[1]):\n",
    "            m = seed_seeker.seek_seeds_before_after(\n",
    "                s_before, s_before + 1,\n",
    "                banner.rate_cumsum,\n",
    "                banner_units_int,\n",
    "                banner.rerollable_rarities,\n",
    "                observed_int,\n",
    "                1\n",
    "            )\n",
    "            if m:\n",
    "                matches.extend(m)\n",
    "        print(f\"Matches found from prior support: {len(matches)} / {len(prior)}\")\n",
    "\n",
    "    if not matches:\n",
    "        raise SystemExit(\"No exact matching seeds found (check banner paste, roll names, version/reroll rules, or search range).\")\n",
    "\n",
    "    # Build posterior over seed_after (this is the new \"seed_before_next_roll\" support)\n",
    "    posterior_after = posterior_from_matches_seed_after(matches, prior_over_seed_before=prior)\n",
    "\n",
    "    # Save if requested\n",
    "    if args.save_pickle:\n",
    "        save_posterior(args.posterior_pkl, posterior_after)\n",
    "        print(f\"Saved posterior with {len(posterior_after)} states to {args.posterior_pkl}\")\n",
    "\n",
    "    # Predict next K from the posterior seed_after states\n",
    "    # IMPORTANT: We are now predicting starting from seed_after values (seed BEFORE next roll),\n",
    "    # so observed_len=0 for this prediction horizon.\n",
    "    pred = predictive_mixture(\n",
    "        posterior_after,\n",
    "        id_to_name,\n",
    "        banner_units_int,\n",
    "        banner.rate_cumsum,\n",
    "        banner.rerollable_rarities,\n",
    "        observed_len=0,\n",
    "        k=args.predict_k,\n",
    "    )\n",
    "\n",
    "    for i in range(min(args.print_pos, len(pred))):\n",
    "        best = topk(pred[i], 6)\n",
    "        s = \", \".join([f\"{u} ({p:.2%})\" for u, p in best])\n",
    "        print(f\"Roll+{i+1:02d}: {s}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc537b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
